---
#
# By default, content added below the "---" mark will appear in the home page
# between the top bar and the list of recent posts.
# To change the home page layout, edit the _layouts/home.html file.
# See: https://jekyllrb.com/docs/themes/#overriding-theme-defaults
# <h3 class="blackpar_title">(Models, Training and Inference)</h3>
layout: home
---
<div style="font-family: 'Source Sans', sans-serif; background: linear-gradient(rgba(255, 255, 255, 0.5), rgba(255, 255, 255, 0.5)), url('images/ireland.jpg') no-repeat; background-size: cover; user-select: none;">
	<center>
		<br><br>
		<h2 class="blackpar_title">SUMAC 2025</h2>
		<h3 class="blackpar_title">The 7<sup>th</sup> workshop on analy<a style="color: rgb(164, 0, 0)">s</a>is, <a style="color: rgb(164, 0, 0)">u</a>nderstanding <br>and pro<a style="color: rgb(164, 0, 0)">m</a>otion of herit<a style="color: rgb(164, 0, 0)">a</a>ge <a style="color: rgb(164, 0, 0)">c</a>ontents</h3>
	    <h4 class="blackpar_title" style="font-family:'Source Pro'; font-weight: 400;"> Advances in machine learning, signal processing, <br>multimodal techniques and human-machine interaction</h4>
		<h5 class="blackpar_title" style="font-family:'Source Pro'; font-weight: 400;"><b>In conjunction with <a href="https://acmmm2025.org/"> ACM Multimedia 2025 </a><br> 27 October, 2025, Dublin, Ireland (On-Site)</b></h5>
		<br><br>	
	</center>
</div>
<br>


<!--
<p style="background-color:#8ef25c;"> <b> Best Paper Award </b> - <em>"Creating a Dataset for the Detection and Segmentation of Degradation Phenomena in Notre-Dame de Paris" </em> - Laura Willot, Kévin Réby, Adeline Manuel, Dan Vodislav, Valerie Gouet-Brunet, Livio De Luca.
<hr  style="color: rgb(92, 242, 117);">
-->

<!-- News and Updates -->
<h2 class="blackpar_title" id="news">News and Updates</h2>
<hr  style="color: rgb(92, 242, 117);">
<p>
<ul>
<!-- 	<li> <b>[19 Dec, 2024]</b> Presentor Slides are now available. Links are provided at the end of the <a href="index.html#schedule">Talk Titles</a></li>
	<li> <b>[06 Nov, 2024]</b> Best paper award goes to <em>"Creating a Dataset for the Detection and Segmentation of Degradation Phenomena in Notre-Dame de Paris" </em><a href="https://dl.acm.org/doi/10.1145/3689094.3689473"> [ACM DL Link]</a>, presented by <b>Laura Willot</b>
	<li> <b>[22 Oct, 2024]</b> <a href="index.html#schedule">Schedule Announced</a></li>
	<li> <b>[22 Oct, 2024]</b> <a href="index.html#accepted_papers">List of Accepted Papers with their links</a></li>
	<li> <b>[20 Aug, 2024]</b> Workshop date announced: 28-Oct, 2024.</li>
	<li> <b>[10 Aug, 2024]</b><a href="https://2024.acmmm.org/important-dates"> Camera-ready paper deadline and Author registration deadline is 22-August-2024.</a></li>
	<li> <b>[10 Aug, 2024]</b><a href="https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/SUMAC"> The paper decisions are released on OpenReview.</a></li>
	<li> <b>[16 July, 2024]</b> <a href="index.html#imp_dates">Deadline Extended to 12.59 PM, 24 July, 2024</a> <a href="https://www.timeanddate.com/worldclock/timezone/utc">UTC-0</a></li>
	<li> <b>[24 June, 2024]</b> <a href="index.html#speakers">Keynote Speakers Announced</a></li>
	<li> <b>[24 June, 2024]</b> <a href="index.html#program_committee">Program Comittee Announced</a></li>
	<li> <b>[17 June, 2024]</b> <a href="index.html#imp_dates">Important Dates</a></li>
	<li> <b>[17 June, 2024]</b> <a href="https://openreview.net/group?id=acmmm.org/ACMMM/2024/Workshop/SUMAC">Submissions Site Open!</a><a href="index.html#submission_guide">Submissions Guidelines.</a></li>
-->
	<li> <b>[30 Oct, 2025]</b> The proceedings are online: <a href="https://dl.acm.org/doi/proceedings/10.1145/3746273" target="new">it's here</a> </li>
	<li> <b>[27 Oct, 2025]</b> Best paper award goes to "Listening to Oral History: Emotion Annotation and Recognition in the ACT UP Oral History Project" <a href="https://dl.acm.org/doi/10.1145/3746273.3760204" target="new"> (ACM DL Link)</a>, presented by <b>Francisca Pessanha</b>. Congratulations! </li>
	<li> <b>[23 Oct, 2025]</b> Zoom for online attendance: it's <a href="https://itam.zoom.us/j/95430040530?pwd=3LTKCVFJITAp00KyGlA5bgG6f3IokN.1">here</a>!</li>
	<li> <b>[6 Oct, 2025]</b> <a href="index.html#schedule">Schedule Announced!</a></li>
	<li> <b>[04 August, 2025]</b> Notifications released!</li>
	<li> <b>[21 July, 2025]</b> Important dates slightly modified, please check</li>
	<li> <b>[11 July, 2025]</b> Short deadline extension! Up to 14 July UTC-0</li>
	<li> <b>[9 March, 2025]</b> <a href="https://sumac-workshops.github.io/2025/">Website Launched!</a></li>
	<li> <b>[3 April, 2025]</b> <a href="https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/SUMAC">Submission site is open!</a></li> 
	<li><b>[11 April, 2025]</b> Deadlines extended.</li>
	<li><b>[26 May, 2025]</b> Keynote info updated.</li>
</ul>
</p>
<br>

<h2 class="blackpar_title" id="overview">Overview</h2>
<hr  style="color: rgb(212, 110, 0);">
<p> The seventh version of the SUMAC (analySis, Understanding and proMotion of heritAge Contents) workshop, like its predecessors, focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. </p>

<p> Digital heritage data acquired are naturally massive and address a large diversity of monomodal modalities (text, structured referentials, image, video, 3D, music, sensor data). Their processing and promotion put into light several scientific challenges as well as various new use cases that are of topical interest today for the ACM Multimedia community, both for academics and industries. Like in the previous editions, we will strive to value the sharing of knowledge, algorithms and experiments; and also open source software and open data, by encouraging the submission of articles that promote this sharing policy. </p>
<p> Abundant heritage data is available in the most recent years. Older data, that can be called the big data of the past, are mostly locked -- they currently remain largely “hidden” from the public, in galleries, libraries, archives, museums or data producers' infrastructures. Processing heritage data to increase their visibility will act as a game changer and contribute to a large panel of communities, by enabling an outstanding pool of inter-operable data, not only as a service to citizens but also to public or private actors, by challenging the research methods at the crossing of computer science, artificial intelligence and digital humanities. </p>
<br>
<!-- Call for Papers -->
<h2 class="blackpar_title" id="call_for_papers">Call for Papers</h2>
<hr  style="color: rgb(212, 110, 0);">
<p> The ambition of SUMAC is to bring together researchers and practitioners from different disciplines to share ideas and methods on current trends in the analysis, understanding and promotion of heritage contents. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction. We welcome research contributions for the following (but not limited to) topics: </p>

<ul>
	<li> Monomodal analysis: image, text, video, 3D, music, sensor data and structured referentials</li>
	<li> Information retrieval for multimedia heritage</li>
	<li> Automated archaeology and heritage data processing</li>
	<li> Multi-modal deep learning and time series analysis for heritage data</li>
	<li> Heritage modeling, visualization, and virtualization</li>
	<li> Smart digitization and reconstruction of heritage data</li>
	<li> Open heritage data and bench-marking</li>
</ul>

<p>The scope of targeted applications is extensive and includes:</p>
<ul>
	<li>Analysis, archaeometry of artifacts</li>
	<li> Diagnosis and monitoring for restoration and preventive conservation</li>
	<li> Geosciences / Geomatics for cultural heritage</li>
	<li> Education</li>
	<li> Smart and sustainable tourism </li>
	<li> Urban planning</li>
	<li> Digital Twins</li>
</ul>
<br>

<h2 class="blackpar_title" id="imp_dates">Important dates (tentative)</h2>
<hr  style="color: rgb(212, 110, 0);">
<ul>
 	<li>Paper submission: <b><del>June 13</del> <del>July 11</del> July 14, 2025 <a href="https://www.timeanddate.com/worldclock/timezone/utc">UTC-0</a></b></li>
	<li>Author acceptance notification: <del>July 24</del> August 4, 2025</li>
	<li>Camera-Ready: <del>August 3</del> August 20, 2025</li>
	<li>Workshop date: Oct. 27, 2025</li>
</ul>
<br>

<h2 class="blackpar_title" id="submission_guide">Submission guidelines</h2>
<hr  style="color: rgb(212, 110, 0);">
<p><b>Submission format</b>  All submissions must be original work not under review at any other workshop, conference, or journal. The workshop will accept papers describing completed work (full paper) as well as work in progress (short paper). Two submission formats are accepted:
<ul>
 <li> 4 pages plus 1-page reference (short paper);</li>
 <li> 8 pages plus up to 2-page reference (full paper).</li>
</ul> 
  They must be encoded as PDF using the ACM Article Template of the main conference ACM Multimedia 2025 <a href="https://acmmm2025.org/information-for-authors/"> (https://acmmm2025.org/information-for-authors/)</a>.
</p>

<p><b>Peer Review and publication in ACM Digital Library</b> Paper submissions must conform with the “double-blind” review policy. All papers will be peer-reviewed by experts in the field, they will receive at least two reviews. Acceptance will be based on relevance to the workshop, scientific novelty, and technical quality. Depending on the number, maturity and topics of the accepted submissions, the work will be presented via oral or poster sessions. The workshop papers will be published in the ACM Digital Library.
</p>

<p><b>Profile Registration</b> A registered profile at OpenReview (submissions' portal) is required to submit a paper.
</p>
IMP NOTES:
<ul>
	<li> New profiles created without an institutional email will go through a moderation process that can take up to two weeks.</li>
	<li> New profiles created with an institutional email will be activated automatically.</li>
</ul>
<p><b>Submissions' Site</b> <a href="https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/SUMAC">https://openreview.net/group?id=acmmm.org/ACMMM/2025/Workshop/SUMAC</a>
</p><br>

<!-- Special Highlights -->
<h2 class="blackpar_title" id="highlights">Special Highlights</h2>
<hr  style="color: rgb(212, 110, 0);">
<p> <b>Best Paper Award - </b>We will present a best paper award, accompanied with a certificate and a trophy, similar to previous editions. </p>

<!-- <p> <b>Journal Special Issue - </b>Authors of the best papers from SUMAC 2023 will be invited to submit an extended and improved version for consideration for Special Issue on Cultural Heritage in the Springer journal Multimedia Tools and Applications.</p>
-->
<br>

<!--Confirmed Speakers-->
<h2 class="blackpar_title" id="speakers">Keynote Speakers</h2>
<hr  style="color: rgb(212, 110, 0);">
<p>
{% include speakers.html %}
</p>
<br>


<h2 class="blackpar_title" id="accepted_papers">Accepted Papers</h2>
<hr  style="color: rgb(212, 110, 0);">
<p>
<ul>
<li> <b>Oral</b></li>
<ul> 
	<li><i>Transparent Similarity Estimation of Medieval Pen Flourishing via Local Visual Patterns</i> - Florian Kibler, Monica Apellaniz-Portos, Max Theisen, Victor Adriel de Jesus Oliveira, Martin Haltrich, Matthias Zeppelzauer, Markus Seidl</li>
	<li> 
		<i>Listening to Oral History: Emotion Annotation and Recognition in the ACT UP Oral History Project</i> - Francisca Pessanha, Ian Padovani, Justus Klaveren, Heysem Kaya, Almila Akdag, Judith Masthoff 
		<a href="https://dl.acm.org/doi/10.1145/3746273.3760204" target="new">(proceedings)</a>
		<a href="papers/slides/SUMAC_Francisca_Pessanha.pdf" target="new"> (presentation)</a>
	</li> 
	<li> 
		<i>Composed Image Retrieval For Visual Localization: Evaluation For Architectural Contents</i> - Emile Blettery, Valerie Gouet-Brunet, Livio De Luca
		<a href="https://dl.acm.org/doi/10.1145/3746273.3760200" target="new">(proceedings)</a>
		<a href="papers/slides/PresentationSumac2025_Blettery_Static.pdf" target="new"> (presentation)</a>
	</li>
	<li> 
		<i>Improved Bag of Time Model with Feature Fusion</i> - Li Weng, Qianneng Wang, Xizhe Wang, Bingya Wu
		<a href="https://dl.acm.org/doi/10.1145/3746273.3760206" target="new">(proceedings)</a>
		<a href="papers/slides/Improved_ Li_Weng.pdf" target="new"> (presentation)</a>
	</li>
	<li> 
		<i>CineSearcher - A Multimodal Film Exploration Workspace</i> - Tobias Kreten, Marta Kipke
		<a href="https://dl.acm.org/doi/10.1145/3746273.3760207" target="new">(proceedings)</a>
		<a href="papers/slides/CineSearcher.pdf" target="new"> (presentation)</a>
	</li>
	<li> <i>DGME-T: Directional Grid Motion Encoding for Transformer-Based Historical Camera Movement Classification</i> - Tingyu Lin, Armin Dadras, Florian Kleber, Robert Sablatnig</li>
</ul>
<li> <b>Poster</b></li>
<ul>
	<li> <i>Benchmarking OCR Tools for Historical Postcards: A Dataset and Evaluation</i> - Matthieu Pelingre and Salvatore Tabbone</li>
	<li> <i>Rule-of-Thirds Detection with Interpretable Geometric Features</i> - Armin Dadras, Tingyu Lin, Robert Sablatnig, Markus Seidl</li>
	<li> <i>An Advanced Digital Twin Approach for Iconographic Heritage Modeling and Processing</i> - Fabrizio Amarilli, Matthias Alfeld, Gian Piero Zarri</li>
	<li> <i>Virtual Reality in Cultural Heritage: A Case Study of Roman Glass Artifacts from Troia, Portugal</i> - Ana Antunes, Armanda Rodrigues, Inês Coutinho, Nuno Correia, Inês Vaz Pinto </li>
</ul>
</ul>
<br>

<!-- Schedule -->

<h2 class="blackpar_title" id="schedule">Schedule (Dublin local time, 27 October) </h2>
<hr  style="color: rgb(212, 110, 0);">
<!-- <p> <b>Keynotes</b>: 40 min talk + 10 min Q&A</p> 
<p> <b>Orals</b>: 20 min talk + 5 min Q&A</p> 
<p> <b>Posters</b>: 10 min talk + 3 min Q&A</p>
<hr  style="color: rgb(212, 110, 0);">
<p>
{% include schedule.html %}
</p> -->
<p> <b>Zoom for online attendance:</b> <a href="https://itam.zoom.us/j/95430040530?pwd=3LTKCVFJITAp00KyGlA5bgG6f3IokN.1">here</a></p>
<img src="images/SUMAC25_schedule.png" width="80%">
<br> <br>

<!-- Technical Committee -->
<h2 class="blackpar_title" id="program_committee">Program Committee</h2>
<hr  style="color: rgb(212, 110, 0);">
<p>
{% include program_committee.html %}
</p>
<br>

<!-- Organizers -->
<h2 class="blackpar_title" id="organizers">Organizers</h2>
<hr  style="color: rgb(212, 110, 0);">
<p>
{% include organizers.html %}
</p>
<br>



<style>
.vertical-center {
  margin: 0;
  position: absolute;
  top: 50%;
  -ms-transform: translateY(-50%);
  transform: translateY(-50%);
}
</style>

<h2 class="blackpar_title">Sponsors</h2>
<hr>
<div class="row">
	<div class="col">
		<center>
			<a href="https://agape-anr.github.io/"> <img src="images/logo_AGAPE.png" width="130px"> </a>
		</center>
	</div>
	<div class="col">
		<center>
			<a href="https://www.timemachine.eu/"> <img src="images/TM-logo.png" width="256px"> </a>
		</center>
	</div>
	<div class="col">
		<center>		
			<a href="https://www.itam.mx/"> <img src="images/logo-ITAM-verde-1.png" width="120px"> </a>
		</center>
	</div>
	<div class="col">
		<center>
			<a href="http://www.zfc.edu.cn/"> <img src="images/logo_zfc.png" width="120px"> </a>
		</center>
	</div>
</div>
<br>

<!-- <h2 class="blackpar_title">Gold Sponsor</h2>
<div class="row">
	<div class="col">
		<center>
			<img src="images/BASF_logo.png" width="250px">
		</center>
	</div>
	<div class="col">
		<center>
			<img src="images/rbc_logo.svg" width="250px">
		</center>
	</div>
</div> -->

<!-- Technical Committee -->
<h2 class="blackpar_title" id="previous_editions">Previous Editions</h2>
<hr>
<p>
{% include previous_editions.html %}
</p>
